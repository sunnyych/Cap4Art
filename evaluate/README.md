# Caption Evaluation with COCO Metrics

This  script, `evaluate_captions.py`, is for evaluating generated image captions using MS COCO metrics such as **CIDEr**, **BLEU**, **METEOR**, and **ROUGE-L**.

---

## üìÑ Contents

- `evaluate_captions.py`: Evaluates generated captions against reference (ground-truth) captions using COCO metrics.

---

## ‚öôÔ∏è Dependencies

You need the **COCO caption evaluation toolkit** and some Python libraries to run the script.

### 1. Clone the COCO Evaluation Toolkit

```bash
git clone https://github.com/tylin/coco-caption.git


